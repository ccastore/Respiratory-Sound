{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Respiratory Sound.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHLRlyMxRjGrrrCy68jpsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccastore/Respiratory-Sound/blob/main/Respiratory_Sound.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparative study of sampling methods on sound respiratory data set\n",
        "\n",
        "Pre-processing:\n",
        "*   Empirical Mode Decomposition (EMD)\n",
        "*   Discrete wavelet decomposition (DWT)\n",
        "\n",
        "Features Extracted:\n",
        "\n",
        "\n",
        "*   Mel Frequency Cepstral Coefficient (MFFC)\n",
        "*   Gammatone Cepstral Coeficients (GFCC)\n",
        "*   CepstralFeatures (CD) \n",
        "\n",
        "Clasifiers:\n",
        "\n",
        "*   Quadratic Discriminant (QD)\n",
        "*   Multilayer Perceptron (MLP)\n",
        "*   Convolutional Neural Network (CNN)\n",
        "*   Recurrent Neural Network (RNN)\n",
        "\n",
        "Sampling Methods:\n",
        "\n",
        "*   Random Over Sampling (ROS)\n",
        "*   Synthetic Minority Over-sampling Technique (SMOTE)\n",
        "*   Synthetic Minority Over-sampling Technique- Willson Edition (SMOTE-ENN)\n",
        "*   Synthetic Minority Over-sampling Technique- Border Line (SMOTE-BL)\n",
        "*   Adaptive Synthetic Sampling (ADASYN)\n",
        "*   Data Augmentation\n",
        " *  Loudness augmentation\n",
        " *  Mask augmentation\n",
        " *  Shift augmentation\n",
        " *  Speed augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "6yMs7_2LeQg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modules\n",
        "import numpy as np\n",
        "import librosa as lb\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tabulate\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, cohen_kappa_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "!pip install audiomentations\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, TimeMask\n",
        "\n",
        "!pip install -U spafe\n",
        "from spafe.features import gfcc\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-njzE6iwZHXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f18df9-cdab-4587-fd56-964a7ffd573d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.20.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: librosa<=0.8.1,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (0.8.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.19.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (1.0.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.1,>=0.6.1->audiomentations) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<=0.8.1,>=0.6.1->audiomentations) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<=0.8.1,>=0.6.1->audiomentations) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa<=0.8.1,>=0.6.1->audiomentations) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa<=0.8.1,>=0.6.1->audiomentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<=0.8.1,>=0.6.1->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa<=0.8.1,>=0.6.1->audiomentations) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<=0.8.1,>=0.6.1->audiomentations) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.1,>=0.6.1->audiomentations) (3.0.4)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.20.0\n",
            "Collecting spafe\n",
            "  Downloading spafe-0.1.2-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.4.1)\n",
            "Installing collected packages: spafe\n",
            "Successfully installed spafe-0.1.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JOiwU374VuYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abd2291-861e-4bc2-a71e-38a9ed0ae57f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Data Collector          : 100%|\u001b[34m███████████████████\u001b[0m| 6898/6898 [00:00<00:00, 116539.89it/s]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feature Extraction Train: 100%|\u001b[34m█████████████████████\u001b[0m| 13731/13731 [21:00<00:00, 10.90it/s]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Feature Extraction Test : 100%|\u001b[34m███████████████████████\u001b[0m| 1271/1271 [00:32<00:00, 39.34it/s]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sampling_method         : COMPLETE\n",
            "\n",
            "RNN training\n",
            "\n",
            "Epoch 1/50\n",
            "215/215 [==============================] - 182s 779ms/step - loss: 0.6643 - accuracy: 0.6986 - val_loss: 4.4350 - val_accuracy: 0.0409 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "215/215 [==============================] - 165s 769ms/step - loss: 0.3558 - accuracy: 0.8698 - val_loss: 4.2045 - val_accuracy: 0.0409 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "215/215 [==============================] - 165s 768ms/step - loss: 0.2197 - accuracy: 0.9270 - val_loss: 0.3815 - val_accuracy: 0.8537 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "215/215 [==============================] - 165s 768ms/step - loss: 0.1662 - accuracy: 0.9452 - val_loss: 0.2179 - val_accuracy: 0.9308 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "215/215 [==============================] - 165s 767ms/step - loss: 0.1258 - accuracy: 0.9598 - val_loss: 0.3208 - val_accuracy: 0.9331 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "215/215 [==============================] - 165s 767ms/step - loss: 0.1108 - accuracy: 0.9629 - val_loss: 0.6616 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "215/215 [==============================] - 165s 768ms/step - loss: 0.0937 - accuracy: 0.9680 - val_loss: 0.2515 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "136/215 [=================>............] - ETA: 59s - loss: 0.0455 - accuracy: 0.9862"
          ]
        }
      ],
      "source": [
        "#@title Configuration\n",
        "#@markdown ---\n",
        "#@markdown Audio\n",
        "data_url = \"/content/drive/MyDrive/Audio ICBHI/processed_audio_files\" #@param {type:\"string\"}\n",
        "Features = \"MFCC\" #@param [\"MFCC\",\"GFCC\",\"CD\"] {type:\"string\"}\n",
        "Number_F =  64#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Classes\n",
        "CORP = True #@param {type:\"boolean\"}\n",
        "Pneumonia = True #@param {type:\"boolean\"}\n",
        "Healthy = True #@param {type:\"boolean\"}\n",
        "URTI = False #@param {type:\"boolean\"}\n",
        "Asthma = False #@param {type:\"boolean\"}\n",
        "LRTI = False #@param {type:\"boolean\"}\n",
        "Bronchiectasis = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Classifier\n",
        "\n",
        "Samplig_method = \"DATA AUGMENTATION\" #@param [\"None\", \"ROS\", \"SMOTE\", \"SMOTE-ENN\", \"SMOTE-BL\", \"ADASYN\", \"DATA AUGMENTATION\"] {type:\"string\"}\n",
        "Classifier_method = \"RNN\" #@param [\"MLP\",\"CNN\",\"RNN\",\"QD\"] {type:\"string\"}\n",
        "Train_value = 80 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Epochs = 50 #@param {type:\"slider\", min:10, max:200, step:10}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Results\n",
        "Matrix_Train = False #@param {type:\"boolean\"}\n",
        "Matrix_Test = True #@param {type:\"boolean\"}\n",
        "ROC_Test = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Experimental\n",
        "Seed = 32 #@param {type:\"number\"}\n",
        "\n",
        "programa()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_class(CORP, Pneumonia,Healthy,URTI,Asthma,LRTI,Bronchiectasis):\n",
        "  class_list=[]\n",
        "  if CORP: class_list.append(\"COPD\")\n",
        "  if Pneumonia: class_list.append(\"Pneumonia\")\n",
        "  if Healthy:class_list.append(\"Healthy\")\n",
        "  if URTI:class_list.append(\"URTI\")\n",
        "  if Asthma:class_list.append(\"Asthma\")\n",
        "  if LRTI:class_list.append(\"LRTI\")\n",
        "  if Bronchiectasis:class_list.append(\"Bronchiectasis\")\n",
        "  return class_list\n",
        "\n",
        "\n",
        "def list_samples(data_url, class_list):\n",
        "  audio_file=[]\n",
        "  audio_class=[]\n",
        "  dises={\n",
        "  '101' : 'URTI',\n",
        "  '102' : 'Healthy',\n",
        "  '103' : 'Asthma',\n",
        "  '104' : 'COPD',\n",
        "  '105' : 'URTI',\n",
        "  '106' : 'COPD',\n",
        "  '107' : 'COPD',\n",
        "  '108' : 'LRTI',\n",
        "  '109' : 'COPD',\n",
        "  '110' : 'COPD',\n",
        "  '111' : 'Bronchiectasis',\n",
        "  '112' : 'COPD',\n",
        "  '113' : 'COPD',\n",
        "  '114' : 'COPD',\n",
        "  '115' : 'LRTI',\n",
        "  '116' : 'Bronchiectasis',\n",
        "  '117' : 'COPD',\n",
        "  '118' : 'COPD',\n",
        "  '119' : 'URTI',\n",
        "  '120' : 'COPD',\n",
        "  '121' : 'Healthy',\n",
        "  '122' : 'Pneumonia',\n",
        "  '123' : 'Healthy',\n",
        "  '124' : 'COPD',\n",
        "  '125' : 'Healthy',\n",
        "  '126' : 'Healthy',\n",
        "  '127' : 'Healthy',\n",
        "  '128' : 'COPD',\n",
        "  '129' : 'URTI',\n",
        "  '130' : 'COPD',\n",
        "  '131' : 'URTI',\n",
        "  '132' : 'COPD',\n",
        "  '133' : 'COPD',\n",
        "  '134' : 'COPD',\n",
        "  '135' : 'Pneumonia',\n",
        "  '136' : 'Healthy',\n",
        "  '137' : 'URTI',\n",
        "  '138' : 'COPD',\n",
        "  '139' : 'COPD',\n",
        "  '140' : 'Pneumonia',\n",
        "  '141' : 'COPD',\n",
        "  '142' : 'COPD',\n",
        "  '143' : 'Healthy',\n",
        "  '144' : 'Healthy',\n",
        "  '145' : 'COPD',\n",
        "  '146' : 'COPD',\n",
        "  '147' : 'COPD',\n",
        "  '148' : 'URTI',\n",
        "  '149' : 'Bronchiolitis',\n",
        "  '150' : 'URTI',\n",
        "  '151' : 'COPD',\n",
        "  '152' : 'Healthy',\n",
        "  '153' : 'Healthy',\n",
        "  '154' : 'COPD',\n",
        "  '155' : 'COPD',\n",
        "  '156' : 'COPD',\n",
        "  '157' : 'COPD',\n",
        "  '158' : 'COPD',\n",
        "  '159' : 'Healthy',\n",
        "  '160' : 'COPD',\n",
        "  '161' : 'Bronchiolitis',\n",
        "  '162' : 'COPD',\n",
        "  '163' : 'COPD',\n",
        "  '164' : 'URTI',\n",
        "  '165' : 'URTI',\n",
        "  '166' : 'COPD',\n",
        "  '167' : 'Bronchiolitis',\n",
        "  '168' : 'Bronchiectasis',\n",
        "  '169' : 'Bronchiectasis',\n",
        "  '170' : 'COPD',\n",
        "  '171' : 'Healthy',\n",
        "  '172' : 'COPD',\n",
        "  '173' : 'Bronchiolitis',\n",
        "  '174' : 'COPD',\n",
        "  '175' : 'COPD',\n",
        "  '176' : 'COPD',\n",
        "  '177' : 'COPD',\n",
        "  '178' : 'COPD',\n",
        "  '179' : 'Healthy',\n",
        "  '180' : 'COPD',\n",
        "  '181' : 'COPD',\n",
        "  '182' : 'Healthy',\n",
        "  '183' : 'Healthy',\n",
        "  '184' : 'Healthy',\n",
        "  '185' : 'COPD',\n",
        "  '186' : 'COPD',\n",
        "  '187' : 'Healthy',\n",
        "  '188' : 'URTI',\n",
        "  '189' : 'COPD',\n",
        "  '190' : 'URTI',\n",
        "  '191' : 'Pneumonia',\n",
        "  '192' : 'COPD',\n",
        "  '193' : 'COPD',\n",
        "  '194' : 'Healthy',\n",
        "  '195' : 'COPD',\n",
        "  '196' : 'Bronchiectasis',\n",
        "  '197' : 'URTI',\n",
        "  '198' : 'COPD',\n",
        "  '199' : 'COPD',\n",
        "  '200' : 'COPD',\n",
        "  '201' : 'Bronchiectasis',\n",
        "  '202' : 'Healthy',\n",
        "  '203' : 'COPD',\n",
        "  '204' : 'COPD',\n",
        "  '205' : 'COPD',\n",
        "  '206' : 'Bronchiolitis',\n",
        "  '207' : 'COPD',\n",
        "  '208' : 'Healthy',\n",
        "  '209' : 'Healthy',\n",
        "  '210' : 'URTI',\n",
        "  '211' : 'COPD',\n",
        "  '212' : 'COPD',\n",
        "  '213' : 'COPD',\n",
        "  '214' : 'Healthy',\n",
        "  '215' : 'Bronchiectasis',\n",
        "  '216' : 'Bronchiolitis',\n",
        "  '217' : 'Healthy',\n",
        "  '218' : 'COPD',\n",
        "  '219' : 'Pneumonia',\n",
        "  '220' : 'COPD',\n",
        "  '221' : 'COPD',\n",
        "  '222' : 'COPD',\n",
        "  '223' : 'COPD',\n",
        "  '224' : 'Healthy',\n",
        "  '225' : 'Healthy',\n",
        "  '226' : 'Pneumonia'}\n",
        "\n",
        "  contenido= os.listdir(data_url)\n",
        "  for con in tqdm(contenido, desc=\"Data Collector          \",ncols=90, colour=\"Blue\"):\n",
        "    if \".wav\" in con:\n",
        "      if dises[con.split(\"_\")[0]] in class_list:\n",
        "        audio_file.append(con)\n",
        "        audio_class.append(dises[con.split(\"_\")[0]])\n",
        "\n",
        "  #eje_x = class_list\n",
        "  #eje_y = []\n",
        "  #for c in class_list:\n",
        "  #  eje_y.append(Counter(audio_class)[c])\n",
        "  #plt.bar(eje_x, eje_y, color=\"blue\")\n",
        "  #plt.ylabel(\"Samples\")\n",
        "  #plt.xlabel(\"Class\")  \n",
        "  #plt.show()\n",
        "  return audio_file, audio_class\n",
        "\n",
        "\n",
        "def Features_extractor(audio_file, Samplig_method, Features, type_tt):\n",
        "    augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    TimeStretch(min_rate=0.5, max_rate=2, p=0.5),\n",
        "    ])\n",
        "\n",
        "    soundArr,sample_rate=lb.load(data_url+\"/\"+audio_file)\n",
        "    if Samplig_method == \"DATA AUGMENTATION\" and type_tt==\"TRAIN\":\n",
        "      soundArr = augment(samples=soundArr, sample_rate=sample_rate)\n",
        "\n",
        "    if Features==\"MFCC\":\n",
        "      features_=lb.feature.mfcc(y=soundArr,sr=sample_rate, n_mfcc=Number_F)\n",
        "    elif Features==\"GFCC\":\n",
        "      features_= np.transpose(gfcc.gfcc(soundArr,22050, win_len=1, num_ceps=Number_F, nfilts=128))\n",
        "    elif Features==\"CD\":\n",
        "      mfcc_=lb.feature.mfcc(y=soundArr,sr=sample_rate, n_mfcc=Number_F)\n",
        "      gfcc_=np.transpose(gfcc.gfcc(soundArr,22050, win_len=1, num_ceps=Number_F, nfilts=128))\n",
        "      cd_mfcc=np.mean(mfcc_,1)\n",
        "      cd_gfcc=np.mean(gfcc_,1)\n",
        "      features_= np.hstack((cd_mfcc,cd_gfcc))\n",
        "    return features_\n",
        "\n",
        "def Train_Test(audio_file, audio_class):\n",
        "  le=LabelEncoder()\n",
        "  clas_audio=le.fit_transform(audio_class)\n",
        "  audios_train,audios_test,y_train,y_test=train_test_split(audio_file,clas_audio,test_size=1-(Train_value/100), random_state=Seed)\n",
        "  return audios_train,audios_test,y_train,y_test,le\n",
        "\n",
        "def Train_features(audios_train,y_train):\n",
        "  data_train=[]\n",
        "  clas_train=[]\n",
        "  for i in tqdm(range(len(audios_train)), desc=\"Feature Extraction Train\",ncols=90, colour=\"Blue\"):\n",
        "    try:\n",
        "      data_train.append(Features_extractor(audios_train[i], Samplig_method, Features, \"TRAIN\"))\n",
        "      clas_train.append(y_train[i])\n",
        "    except:\n",
        "      pass\n",
        "  data_train=tf.convert_to_tensor(data_train)\n",
        "  clas_train=tf.convert_to_tensor(clas_train)\n",
        "  return data_train,clas_train\n",
        "\n",
        "def Test_features(audios_test,y_test):\n",
        "  data_test=[]\n",
        "  clas_test=[]\n",
        "  for i in tqdm(range(len(audios_test)), desc=\"Feature Extraction Test \",ncols=90, colour=\"Blue\"):\n",
        "    try:\n",
        "      data_test.append(Features_extractor(audios_test[i], Samplig_method, Features, \"TEST\"))\n",
        "      clas_test.append(y_test[i])\n",
        "    except:\n",
        "      pass\n",
        "  data_test=tf.convert_to_tensor(data_test)\n",
        "  clas_test=tf.convert_to_tensor(clas_test)\n",
        "  return data_test,clas_test\n",
        "\n",
        "def MLP_train(x_train_s, y_train_s,x_test, y_test):\n",
        "  my_callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_lr=0.00001,mode='min')\n",
        "        ]\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  input=tf.keras.layers.Input(shape=(x_train_s.shape[1],x_train_s.shape[2],1), name=\"Input_Spectro\")\n",
        "\n",
        "  x= tf.keras.layers.Flatten()(input)\n",
        "  x= tf.keras.layers.BatchNormalization()(x)\n",
        "  x= tf.keras.layers.Dense(20,activation='relu', name=\"Dense_1\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_1\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(10,activation='relu', name=\"Dense_2\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_2\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(6,activation='relu', name=\"Dense_3\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_3\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(5,activation='relu', name=\"Dense_5\")(x)\n",
        "  x= tf.keras.layers.Dense(4,activation='relu', name=\"Dense_8\")(x)\n",
        "\n",
        "  output= tf.keras.layers.Dense(3,activation='softmax', name=\"Dense_9\")(x)\n",
        "  MLP=tf.keras.Model(input, output, name=\"Output\")\n",
        "  MLP.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history=MLP.fit(\n",
        "      x_train_s,\n",
        "      y_train_s,\n",
        "      validation_data=(x_test,y_test),\n",
        "      #batch=32,\n",
        "      epochs=Epochs,verbose=1,\n",
        "      callbacks=my_callbacks\n",
        "  )\n",
        "  predict_test_=MLP.predict(x_test)\n",
        "  predict_test=np.argmax(predict_test_, axis=1)\n",
        "  cm = confusion_matrix(y_test, predict_test)\n",
        "  acc=accuracy_score(y_test, predict_test) \n",
        "  kappa = cohen_kappa_score(y_test, predict_test)\n",
        "\n",
        "  sort_list=np.sort(class_list)\n",
        "  for i in range(np.max(predict_test)+1):\n",
        "    #print(\"Class\",i)\n",
        "    n_y=tf.cast(y_test==i,dtype=tf.int16)\n",
        "    roc=roc_curve(n_y.numpy(), predict_test_[:,i])\n",
        "    plt.plot(roc[0],roc[1])\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic Curve'+\" (\"+sort_list[i]+\")\")\n",
        "    plt.show()\n",
        "\n",
        "  results={\"matrix\":cm,\"acc\":acc,\"kappa\":kappa}\n",
        "  return results\n",
        "\n",
        "\n",
        "def CNN_train(x_train_s, y_train_s,x_test, y_test):\n",
        "  my_callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_lr=0.00001,mode='min')\n",
        "        ]\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  input=tf.keras.layers.Input(shape=(x_train_s.shape[1],x_train_s.shape[2],1), name=\"Input_Spectro\")\n",
        "  x= tf.keras.layers.Conv2D(16,(2,2), name=\"Conv2D_1\")(input)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_1\")(x)\n",
        "  x= tf.keras.layers.MaxPooling2D(pool_size=2,padding='valid', name=\"MaxPooling_1\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_1\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Conv2D(32,(2,2), name=\"Conv2D_2\")(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_2\")(x)\n",
        "  x= tf.keras.layers.MaxPooling2D(pool_size=2,padding='valid', name=\"MaxPooling_2\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_2\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Conv2D(64,(2,2), name=\"Conv2D_3\")(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_3\")(x)\n",
        "  x= tf.keras.layers.MaxPooling2D(pool_size=2,padding='valid', name=\"MaxPooling_3\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_3\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Conv2D(128,(2,2), name=\"Conv2D_4\")(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_4\")(x)\n",
        "  x= tf.keras.layers.MaxPooling2D(pool_size=2,padding='valid', name=\"MaxPooling_4\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_4\")(x)\n",
        "\n",
        "  x= tf.keras.layers.GlobalAveragePooling2D(name=\"AveragePooling2D\")(x)\n",
        "  output= tf.keras.layers.Dense(3, name=\"Dense\", activation=\"softmax\")(x)\n",
        "\n",
        "  CNN=tf.keras.Model(input, output, name=\"Output\")\n",
        "  CNN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  history=CNN.fit(\n",
        "      x_train_s,\n",
        "      y_train_s,\n",
        "      validation_data=(x_test,y_test),\n",
        "      epochs=Epochs,verbose=1,batch_size=16,\n",
        "      callbacks=my_callbacks\n",
        "  )\n",
        "\n",
        "  predict_test_=CNN.predict(x_test)\n",
        "  predict_test=np.argmax(predict_test_, axis=1)\n",
        "  cm = confusion_matrix(y_test, predict_test)\n",
        "  acc=accuracy_score(y_test, predict_test) \n",
        "  #recall=recall_score(y_test, predict_test)\n",
        "  kappa = cohen_kappa_score(y_test, predict_test)\n",
        "\n",
        "  sort_list=np.sort(class_list)\n",
        "  for i in range(np.max(predict_test)+1):\n",
        "    #print(\"Class\",i)\n",
        "    n_y=tf.cast(y_test==i,dtype=tf.int16)\n",
        "    roc=roc_curve(n_y.numpy(), predict_test_[:,i],)\n",
        "    plt.plot(roc[0],roc[1])\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic Curve'+\" (\"+sort_list[i]+\")\")\n",
        "    plt.show()\n",
        "\n",
        "  results={\"matrix\":cm,\"acc\":acc,\"kappa\":kappa}\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def RNN_train(x_train_s, y_train_s,x_test, y_test):\n",
        "  my_callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_lr=0.00001,mode='min')\n",
        "        ]\n",
        "  tf.keras.backend.clear_session()\n",
        "  input=tf.keras.layers.Input(shape=(x_train_s.shape[1],x_train_s.shape[2],1), name=\"Input_Spectro\")\n",
        "  x=tf.keras.layers.BatchNormalization()(input)\n",
        "  x=tf.keras.layers.Conv2D(64,(4,1),padding='same')(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_1\")(x)\n",
        "  x= tf.keras.layers.BatchNormalization()(x)\n",
        "  x= tf.keras.layers.AveragePooling2D(pool_size=(2,1),padding='same', name=\"MaxPooling_1\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.1, name=\"Dropout_1\")(x)\n",
        "\n",
        "  x=tf.keras.layers.BatchNormalization()(x)\n",
        "  x=tf.keras.layers.Conv2D(128,(4,1),padding='same')(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_2\")(x)\n",
        "  x= tf.keras.layers.BatchNormalization()(x)\n",
        "  x= tf.keras.layers.AveragePooling2D(pool_size=(2,1),padding='same', name=\"MaxPooling_2\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.15, name=\"Dropout_2\")(x)\n",
        "\n",
        "  x=tf.keras.layers.BatchNormalization()(x)\n",
        "  x=tf.keras.layers.Conv2D(256,(4,1),padding='same')(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_3\")(x)\n",
        "  x= tf.keras.layers.BatchNormalization()(x)\n",
        "  x= tf.keras.layers.AveragePooling2D(pool_size=(4,1),padding='same', name=\"MaxPooling_3\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_3\")(x)\n",
        "\n",
        "  x=tf.keras.layers.BatchNormalization()(x)\n",
        "  x=tf.keras.layers.Conv2D(512,(4,1),padding='same')(x)\n",
        "  x= tf.keras.layers.Activation(tf.keras.activations.relu, name=\"Activation_4\")(x)\n",
        "  x= tf.keras.layers.BatchNormalization()(x)\n",
        "  x= tf.keras.layers.AveragePooling2D(pool_size=(4,1),padding='same', name=\"MaxPooling_4\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.25, name=\"Dropout_4\")(x)\n",
        "  x= tf.squeeze(x,axis=1)\n",
        "\n",
        "  x=tf.keras.layers.Bidirectional(tf.keras.layers.GRU((256),return_sequences=True))(x)\n",
        "  x= tf.expand_dims(x,-1)\n",
        "  x= tf.keras.layers.AveragePooling2D(pool_size=(1,512),padding='same', name=\"MaxPooling_5\")(x)\n",
        "  x= tf.keras.layers.Flatten()(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(256,activation='relu', name=\"Dense_1\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.3, name=\"Dropout_5\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(1024,activation='relu', name=\"Dense_2\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.3, name=\"Dropout_6\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(1024,activation='relu', name=\"Dense_3\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.3, name=\"Dropout_7\")(x)\n",
        "\n",
        "  output= tf.keras.layers.Dense(3,activation='softmax', name=\"Dense_4\")(x)\n",
        "\n",
        "\n",
        "  RNN=tf.keras.Model(input, output, name=\"Output\")\n",
        "  RNN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  #K.set_value(CNN.optimizer.learning_rate, 0.001)\n",
        "\n",
        "  history=RNN.fit(\n",
        "      x_train_s,\n",
        "      y_train_s,\n",
        "      validation_data=(x_test,y_test),\n",
        "      epochs=Epochs,verbose=1,batch_size=64,\n",
        "      callbacks=my_callbacks\n",
        "  )\n",
        "  predict_test_=RNN.predict(x_test)\n",
        "  predict_test=np.argmax(predict_test_, axis=1)\n",
        "  cm = confusion_matrix(y_test, predict_test)\n",
        "  acc=accuracy_score(y_test, predict_test) \n",
        "  kappa = cohen_kappa_score(y_test, predict_test)\n",
        "\n",
        "  sort_list=np.sort(class_list)\n",
        "  for i in range(np.max(predict_test)+1):\n",
        "    #print(\"Class\",i)\n",
        "    n_y=tf.cast(y_test==i,dtype=tf.int16)\n",
        "    roc=roc_curve(n_y.numpy(), predict_test_[:,i])\n",
        "    plt.plot(roc[0],roc[1])\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic Curve'+\" (\"+sort_list[i]+\")\")\n",
        "    plt.show()\n",
        "\n",
        "  results={\"matrix\":cm,\"acc\":acc,\"kappa\":kappa}\n",
        "  return results\n",
        "\n",
        "\n",
        "def MLP_cd_train(x_train_s, y_train_s,x_test, y_test):\n",
        "  my_callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_lr=0.00001,mode='min')\n",
        "        ]\n",
        "  tf.keras.backend.clear_session()\n",
        "  input=tf.keras.layers.Input(shape=(x_train_s.shape[1]), name=\"Input_Spectro\")\n",
        "  #x= tf.keras.layers.Flatten()(input)\n",
        "  x= tf.keras.layers.BatchNormalization()(input)\n",
        "  x= tf.keras.layers.Dense(20,activation='relu', name=\"Dense_1\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_1\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(10,activation='relu', name=\"Dense_2\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_2\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(6,activation='relu', name=\"Dense_3\")(x)\n",
        "  x= tf.keras.layers.Dropout(0.2, name=\"Dropout_3\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(5,activation='relu', name=\"Dense_5\")(x)\n",
        "\n",
        "  x= tf.keras.layers.Dense(4,activation='relu', name=\"Dense_8\")(x)\n",
        "  output= tf.keras.layers.Dense(np.max(y_train_s)+1,activation='softmax', name=\"Dense_9\")(x)\n",
        "\n",
        "  MLP=tf.keras.Model(input, output, name=\"Output\")\n",
        "\n",
        "  MLP.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  history=MLP.fit(\n",
        "      x_train_s,\n",
        "      y_train_s,\n",
        "      validation_data=(x_test,y_test),\n",
        "      #batch=32,\n",
        "      epochs=Epochs,verbose=1,\n",
        "      callbacks=my_callbacks\n",
        "  )\n",
        "\n",
        "  predict_test_=MLP.predict(x_test)\n",
        "  predict_test=np.argmax(predict_test_, axis=1)\n",
        "  cm = confusion_matrix(y_test, predict_test)\n",
        "  acc=accuracy_score(y_test, predict_test) \n",
        "  #recall=recall_score(y_test, predict_test)\n",
        "  kappa = cohen_kappa_score(y_test, predict_test)\n",
        "\n",
        "  sort_list=np.sort(class_list)\n",
        "  for i in range(np.max(predict_test)+1):\n",
        "    #print(\"Class\",i)\n",
        "    n_y=tf.cast(y_test==i,dtype=tf.int16)\n",
        "    roc=roc_curve(n_y.numpy(), predict_test_[:,i])\n",
        "    plt.plot(roc[0],roc[1])\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic Curve'+\" (\"+sort_list[i]+\")\")\n",
        "    plt.show()\n",
        "\n",
        "  results={\"matrix\":cm,\"acc\":acc,\"kappa\":kappa}\n",
        "  return results\n",
        "\n",
        "\n",
        "def QD_train(x_train_s, y_train_s,x_test, y_test):\n",
        "  clf = QuadraticDiscriminantAnalysis()\n",
        "  clf.fit(x_train_s, y_train_s)  \n",
        "  predict_test=clf.predict(x_test)\n",
        "  cm = confusion_matrix(y_test, predict_test)\n",
        "  \n",
        "  acc=accuracy_score(y_test, predict_test) \n",
        "  kappa = cohen_kappa_score(y_test, predict_test)\n",
        "  results={\"matrix\":cm,\"acc\":acc,\"kappa\":kappa}\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "Xc-t1v6yZZRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global class_list\n",
        "def programa():\n",
        "  global class_list\n",
        "\n",
        "  class_list=list_class(CORP, Pneumonia,Healthy,URTI,Asthma,LRTI,Bronchiectasis)\n",
        "  audio_file, audio_class=list_samples(data_url, class_list)\n",
        "  print()\n",
        "  audios_train,audios_test,y_train,y_test,le=Train_Test(audio_file, audio_class)\n",
        "  if Samplig_method==\"DATA AUGMENTATION\" or Samplig_method==\"ROS\":\n",
        "    ros = RandomOverSampler()\n",
        "    audios_train, y_train = ros.fit_resample(np.array(audios_train).reshape((-1,1)), y_train)\n",
        "    audios_train=audios_train.reshape(-1)\n",
        "  x_train,y_train=Train_features(audios_train,y_train)\n",
        "  print()\n",
        "  x_test,y_test=Test_features(audios_test,y_test)\n",
        "  print()\n",
        "\n",
        "  if Features== \"MFCC\" or Features== \"GFCC\":\n",
        "      if Samplig_method==\"None\" or Samplig_method==\"DATA AUGMENTATION\" or Samplig_method==\"ROS\":\n",
        "          x_train_s=x_train\n",
        "          y_train_s=y_train\n",
        "\n",
        "      elif Samplig_method==\"SMOTE\":\n",
        "          x_train_reshape=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "          smote = SMOTE()\n",
        "          x_train_s, y_train_s = smote.fit_resample(x_train_reshape, y_train)\n",
        "          x_train_s=np.reshape(x_train_s,(x_train_s.shape[0],x_train.shape[1],x_train.shape[2]))\n",
        "\n",
        "      elif Samplig_method==\"ADASYN\":\n",
        "          x_train_reshape=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "          adasyn = ADASYN()\n",
        "          x_train_s, y_train_s = adasyn.fit_resample(x_train_reshape, y_train)\n",
        "          x_train_s=np.reshape(x_train_s,(x_train_s.shape[0],x_train.shape[1],x_train.shape[2]))\n",
        "\n",
        "      elif Samplig_method==\"SMOTE-ENN\":\n",
        "          x_train_reshape=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "          smoteenn = SMOTEENN(n_jobs=-1)\n",
        "          x_train_s, y_train_s = smoteenn.fit_resample(x_train_reshape, y_train)\n",
        "          x_train_s=np.reshape(x_train_s,(x_train_s.shape[0],x_train.shape[1],x_train.shape[2]))\n",
        "\n",
        "      elif Samplig_method==\"SMOTE-BL\":\n",
        "          x_train_reshape=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "          smotebl = BorderlineSMOTE()\n",
        "          x_train_s, y_train_s = smotebl.fit_resample(x_train_reshape, y_train)\n",
        "          x_train_s=np.reshape(x_train_s,(x_train_s.shape[0],x_train.shape[1],x_train.shape[2]))\n",
        "\n",
        "      x_test=np.expand_dims(x_test,-1)\n",
        "      x_train_s=np.expand_dims(x_train_s,-1)\n",
        "      \n",
        "  elif Features==\"CD\":\n",
        "      if Samplig_method==\"None\" or Samplig_method==\"DATA AUGMENTATION\" or Samplig_method==\"ROS\":\n",
        "          x_train_s=x_train\n",
        "          y_train_s=y_train\n",
        "      elif Samplig_method==\"SMOTE\":\n",
        "          smote = SMOTE()\n",
        "          x_train_s, y_train_s = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "      elif Samplig_method==\"ADASYN\":\n",
        "          adasyn = ADASYN()\n",
        "          x_train_s, y_train_s = adasyn.fit_resample(x_train, y_train)\n",
        "\n",
        "      elif Samplig_method==\"SMOTE-ENN\":\n",
        "          smoteenn = SMOTEENN()\n",
        "          x_train_s, y_train_s = smoteenn.fit_resample(x_train, y_train)\n",
        "\n",
        "      elif Samplig_method==\"SMOTE-BL\":\n",
        "          smotebl = BorderlineSMOTE()\n",
        "          x_train_s, y_train_s = smotebl.fit_resample(x_train, y_train)\n",
        "  print(\"Sampling_method         :\",\"COMPLETE\")\n",
        "  print()\n",
        "\n",
        "  if Features!=\"CD\":\n",
        "    if Classifier_method==\"MLP\":\n",
        "      print(\"MLP training\")\n",
        "      print()\n",
        "      metrics=MLP_train(x_train_s, y_train_s,x_test, y_test)\n",
        "    elif Classifier_method==\"CNN\":\n",
        "      print(\"CNN training\")\n",
        "      print()\n",
        "      metrics=CNN_train(x_train_s, y_train_s,x_test, y_test)\n",
        "    elif Classifier_method==\"RNN\":\n",
        "      print(\"RNN training\")\n",
        "      print()\n",
        "      metrics=RNN_train(x_train_s, y_train_s,x_test, y_test)\n",
        "  else:\n",
        "    if Classifier_method==\"MLP\":\n",
        "      print(\"MLP training\")\n",
        "      print()\n",
        "      metrics=MLP_cd_train(x_train_s, y_train_s,x_test, y_test)\n",
        "    if Classifier_method==\"QD\":\n",
        "      print(\"QD training\")\n",
        "      print()\n",
        "      metrics=QD_train(x_train_s, y_train_s,x_test, y_test)\n",
        "  print(metrics)"
      ],
      "metadata": {
        "id": "CzyoZ5a2lnMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}